---
title: "Untitled"
format: uaz-revealjs
editor: visual
---

## Before we get started

You'll need the following R packages today:

```{r}
#| eval: false
#| echo: true

#For making `targets` work:
library(targets)
library(tarchetypes)
library(visNetwork)
library(future)
library(future.callr)

#For our data wrangling and analysis:
library(tidyverse)
library(lubridate)

#for installing demos and course materials:
library(usethis)

```

## Moving Toward Reproducibility

-   Reproducibility vs. replicability

-   Why bother?

    -   For you in the future

    -   For your collaborators

    -   For the greater community

## Scenario 1

> You have a reproducible R project, but to re-run all the code takes several **days** because some of the steps are very slow.
> Your collaborator finds a few mistakes in the data and sends an update and asks you if you can update the plots.
> You probably don't need to re-run *everything*, but that's the easiest route to reproducibility.
> While your code is running, they send another update: "Whoops, missed another mistake!".
> You cringe and reluctantly re-start your analysis running.

::: notes
Replace this with something graphical
:::

## Scenario 2

> You took a previous reproducibility workshop and learned to number R scripts sequentially (e.g. `01-wrangle_data.R`, `02-analysis.R`, etc.).
> This has been working out great for you, but now your current project has too many scripts that can be run independently to keep track of (e.g. `02a-multivariate_analysis.R`, `02b-linear_model.R`, `02c-bayesian_analysis.R`).
> Manually updating the numbering system when you add something new is becoming a burden and you are ready to give up on reproducibility.

::: notes
Replace this with something graphical
:::

## Workflow management

-   what is it

-   steal figs from other people's talks and the targets manual

## Demo

If you want to follow along (recommended), install this project using the following R code

``` r
usethis::use_course("cct-datascience/targets-demo")
```

Please speak up if anything isn't working for you!

::: notes
1.  tar_make()
2.  examine outputs (.docx and with tar_read())
3.  examine \_targets.R & R/
4.  tar_visnetwork()
5.  make a change
6.  tar_visnetwork()
7.  tar_make()
8.  Show \_targets/ and discuss
:::

## Anatomy of a `targets` project

1.  \_targets.R
    -   Configure and define workflow
2.  R/
    -   R script(s) with custom functions
3.  \_targets/
    1.  Generated by `tar_make()`

    2.  Contains intermediate objects

    3.  Should ***not*** be tracked in version control

## Starting a new `targets` project

Use `use_targets()` to set up a brand new project, or convert an existing one to use `targets` .

::: callout-tip
Follow along on your own computer for best learning results!
:::

::: notes
Use .csv that's online so they don't need to download data and demo `tar_url()` ---carpentries maybe?

Have a question to answer so you can write some simple data wrangling functions

Demo sketching out target names at start

Demo sketching out code, transfer to function, run `tar_make()` workflow.
:::

## Refactoring a project to use `targets`

> **refactor**
>
> /rēˈfaktər/
>
> *verb*
>
> 1.  restructure (the source code of an application or piece of software) so as to improve operation without altering functionality.

## Refactoring a project to use `targets`

### To-do:

1.  `use_targets()` to set up infrastructure including `_targets.R`
2.  Convert R script(s) to functions
3.  Write targets
4.  Run `tar_make()`
5.  Debug

Best to do this one target at a time

## Writing functions for `targets`

-   Use a naming convention (verbs are good)
-   Make the function arguments the same as target names
-   The last step usually must *return* something

**BAD:**

``` r
m1 <- function(x) {
  lm(stem_length ~ watershed, data = x)
}
```

**GOOD:**

``` r
fit_model <- function(data_clean) {
  lm(stem_length ~ watershed, data = data_clean)
}
```

## Creating targets

-   Use a naming convention (nouns are good)

-   Use concise but descriptive target names

**BAD:**

-   `data1`, `data2`, `data3`
-   `histogram_by_site_plot`

**GOOD:**

-   `data_file`, `data_raw`, `data_clean`

-   `plot_hist_site`

## Debugging targets

-   Errors in `tar_make()` are usually uninformative because code is run in a separate R session with `callr`.
-   Use `tar_meta()` to access error messages

``` r
tar_meta(fields = error, complete_only = TRUE)
```

## Debugging targets

If the error is in a custom function:

1.  Use `tar_load()` to load necessary targets into environment
2.  Test function in console
3.  Run through code in function interactively

::: notes
Demo this by purposefully introducing an error in the demo project
:::

## Exercise

1.  Install another demo project

``` r
usethis::use_course("cct-datascience/targets-refactor")
```

2.  *Refactor* the project to use `targets`

    -   Run `use_targets()` and create a `tar_plan()`
    -   Turn scripts or portions of scripts into functions in the `R/` folder
    -   Add packages to `tar_option_set(packages = c(…))`
    -   Check workflow with `tar_visnetwork()`
    -   Checking if it works with `tar_make()`
    -   Debug functions if necessary

    ### 
